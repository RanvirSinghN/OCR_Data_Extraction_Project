{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d7a838-3d38-4189-9499-6870f38d2bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import inspect\n",
    "import nbimporter\n",
    "import Extracting_Data_Project\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI() \n",
    "\n",
    "from prompts import (\n",
    "    bank_statement_prompt,\n",
    "    passport_prompt,\n",
    "    council_tax_prompt,\n",
    "    payslip_prompt,\n",
    "    driving_licence_prompt,\n",
    "    accountant_certificate_prompt,\n",
    "    p60_prompt,\n",
    "    tyo_prompt,\n",
    "    sa302_prompt\n",
    ")\n",
    "\n",
    "image_blocks = Extracting_Data_Project.convert_pdf_to_png(r\"C:\\Users\\ranvi\\OneDrive\\Documents\\Test_Data\\P60_1.pdf\")\n",
    "\n",
    "#trying to do extraction using only LLM - gpt model does python for me - quickest \n",
    "times = []\n",
    "for i in range(0,3):\n",
    "    start = time.time()\n",
    "    response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"\"\"You are an extemely high level data analyst and your task is to extract useful information from several different types of documents used in banking. From the images given,\n",
    "            identify what kind of document has been given to you. Only select from one of these options. Bank Statement, Passport, Council Tax, Payslip, Driving Licence, \n",
    "            Accountant Certificate, P60, TYO, SA302. If you are unable to identify one of these documents, then output \"Document not supported.\" and try summarise what this dcument is showing. Take care when distinguishing between SA302 or TYO, the TYO is a less detailed overall\n",
    "            view of the year with totals calculated, meanwhile the SA302 is a break down of taxes paid over the year and a lot more detailed.\"\"\"},\n",
    "            *image_blocks\n",
    "        ]\n",
    "    }]\n",
    "    )\n",
    "    output = response.output_text\n",
    "\n",
    "    response2 = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\":[\n",
    "            {\"type\": \"input_text\", \"text\": \"\"\"You have been given the output of a previous answer from a prompt given by the user which has specified the type of document you are supposed\n",
    "            to analyse and extract information from. You have also been given several python functions that should be used for this task. You have already been given the \n",
    "            image blocks and document_type used in 'handle_file' so you can skip to the document processing. All the functions and strings called in handle-file have also been provided.\n",
    "            Your task is to recreate the string output I would get from running handle_file (ignore the boolean value returned).\"\"\"},\n",
    "            {\"type\": \"input_text\", \"text\": output},\n",
    "            {\"type\":\"input_text\", \"text\": inspect.getsource(Extracting_Data_Project.handle_file)},\n",
    "            {\"type\":\"input_text\", \"text\": inspect.getsource(Extracting_Data_Project.extract_json_from_document)},\n",
    "            {\"type\":\"input_text\", \"text\": bank_statement_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": passport_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": council_tax_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": payslip_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": driving_licence_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": accountant_certificate_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": p60_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": tyo_prompt},\n",
    "            {\"type\":\"input_text\", \"text\": sa302_prompt},\n",
    "            *image_blocks\n",
    "        ]\n",
    "    }]\n",
    "    )\n",
    "    end = time.time()\n",
    "    #print(response2.output_text)\n",
    "    #print(f\"time: {round(end - start,2)}s\")\n",
    "    times.append(end - start)\n",
    "\n",
    "print(round(np.sum(np.array(times))/3,2))\n",
    "\n",
    "#Alot faster using only LLM but slightly less accurate \n",
    "\n",
    "#Human must give document, LLM cant do anything till document given so can't be fully agentic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7acb9fcb-4db2-4323-b78d-d2acee55ee3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1634.26\n"
     ]
    }
   ],
   "source": [
    "#Creating tools as AI agents to carry out extraction\n",
    "\n",
    "#Function calling in API to decide which document is being extracted (using openAI documentation)\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def extract_json_from_document(prompt, image_blocks):\n",
    "    response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": prompt},\n",
    "            *image_blocks\n",
    "        ]\n",
    "    }]\n",
    ")\n",
    "    return(response.output_text)\n",
    "\n",
    "#image_blocks = Extracting_Data_Project.convert_pdf_to_png(r\"C:\\Users\\ranvi\\OneDrive\\Documents\\Test_Data\\bank-statement1.pdf\")\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"extracting_agent\",\n",
    "    \"description\": \"\"\"Takes in images of a document and decides what type of document it is from the list: Bank Statement, Passport, Council Tax, Payslip, Driving Licence, \n",
    "        Accountant Certificate, P60, TYO, SA302 or other. And then extracts specific information from document depending on its type.\"\"\",\n",
    "    \"parameters\":{\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"document_type\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"document_type\"]\n",
    "    }\n",
    "}\n",
    "]\n",
    "\n",
    "def extracting_agent(document_type, images, client):\n",
    "    if document_type == \"Bank Statement\":\n",
    "        return(extract_json_from_document(bank_statement_prompt, images))\n",
    "    \n",
    "    elif document_type == \"Passport\":\n",
    "        return(extract_json_from_document(passport_prompt, images))\n",
    "          \n",
    "    elif document_type == \"Council Tax\":\n",
    "        return(extract_json_from_document(council_tax_prompt, images))\n",
    "        \n",
    "    elif document_type == \"Payslip\":\n",
    "        return(extract_json_from_document(payslip_prompt, images))\n",
    "    \n",
    "    elif document_type == \"Driving Licence\":\n",
    "        return(extract_json_from_document(driving_licence_prompt, images))\n",
    "\n",
    "    elif document_type == \"Accountant Certificate\":\n",
    "        return(extract_json_from_document(accountant_certificate_prompt, images))\n",
    "        \n",
    "    elif document_type == \"P60\":\n",
    "        return(extract_json_from_document(p60_prompt, images))\n",
    "    \n",
    "    elif document_type == \"TYO\":\n",
    "        return(extract_json_from_document(tyo_prompt, images))\n",
    "        \n",
    "    elif document_type == \"SA302\":\n",
    "        return(extract_json_from_document(sa302_prompt, images))\n",
    "    else:\n",
    "        response = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"\"\"You are a high level data extraction model and have been given a document that isn't supported by the\n",
    "                software. You should still try identify what the document is and try summarise it. Your response should start exactly like this \n",
    "                'Document type not supported but document appears to be ......' \"\"\"},\n",
    "                *images\n",
    "            ]\n",
    "        }]\n",
    "    )\n",
    "    return(response.output_text)\n",
    "    \n",
    "def summarise_agent(images):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"\"\"You are a high level data extraction model and have been given a document that isn't supported by the\n",
    "                software. You should still try identify what the document is and try summarise it. Your response should start exactly like this \n",
    "                'Document type not supported but document appears to be ......' \"\"\"},\n",
    "                *images\n",
    "            ]\n",
    "        }]\n",
    "    )\n",
    "    return(response.output_text)\n",
    "times = []\n",
    "for i in range(0,3):\n",
    "    start = time.time()\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input= [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"\"\"Decide what the document is that has been submitted in prompt.\"\"\"},\n",
    "            *image_blocks\n",
    "        ]\n",
    "    }],\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    args = json.loads(response.output[0].arguments)\n",
    "    #print(args[\"document_type\"])\n",
    "    document = args[\"document_type\"]\n",
    "    output=extracting_agent(document, image_blocks, client)\n",
    "    #print(f\"time: {round(end - start,2)}s\")\n",
    "    times.append(end -start)\n",
    "print(round(np.sum(np.array(times))/3,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12a3498-1bdb-4ff3-9529-7cef603caff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.896666666666665\n"
     ]
    }
   ],
   "source": [
    "print((24.02 + 24.67 + 32)/3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
